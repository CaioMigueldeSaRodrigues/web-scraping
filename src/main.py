# src/main.py
# Este √© o script principal que ser√° executado pelo Job no Databricks.

import pandas as pd
from typing import Optional, Tuple, Dict, Any
from .logger_config import get_logger
from .embeddings import processar_embeddings_completos
from .reporting import (
    gerar_relatorio_benchmarking,
    obter_estatisticas_relatorio,
    enviar_email_relatorio
)

logger = get_logger(__name__)


def listar_tabelas_disponiveis() -> dict:
    """
    Lista todas as tabelas dispon√≠veis no cat√°logo para debug.
    
    Returns:
        dict: Informa√ß√µes sobre as tabelas dispon√≠veis
    """
    try:
        tabelas_info = {}
        tabelas_existentes = spark.catalog.listTables()
        
        for table in tabelas_existentes:
            try:
                # Tenta contar registros
                count = spark.table(table.name).count()
                
                # Tenta obter estrutura
                sample = spark.table(table.name).limit(1).toPandas()
                colunas = list(sample.columns) if not sample.empty else []
                
                tabelas_info[table.name] = {
                    "database": table.database,
                    "count": count,
                    "columns": colunas,
                    "type": table.tableType
                }
                
            except Exception as e:
                tabelas_info[table.name] = {
                    "error": str(e),
                    "database": table.database,
                    "type": table.tableType
                }
        
        return tabelas_info
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao listar tabelas: {e}")
        return {}


def validar_parametros_pipeline(
    tabela_magalu: str,
    tabela_bemol: str
) -> bool:
    """
    Valida par√¢metros do pipeline antes da execu√ß√£o.
    
    Args:
        tabela_magalu: Nome da tabela do Magalu
        tabela_bemol: Nome da tabela da Bemol
        
    Returns:
        bool: True se par√¢metros s√£o v√°lidos
    """
    try:
        logger.info(f"üîç Validando par√¢metros do pipeline...")
        logger.info(f"Tabela Magalu: {tabela_magalu}")
        logger.info(f"Tabela Bemol: {tabela_bemol}")
        
        # Verifica se as tabelas existem
        try:
            tabelas_existentes = spark.catalog.listTables()
            nomes_tabelas = [table.name for table in tabelas_existentes]
            logger.info(f"Tabelas dispon√≠veis: {nomes_tabelas}")
            
            if tabela_magalu not in nomes_tabelas:
                logger.error(f"‚ùå Tabela {tabela_magalu} n√£o encontrada")
                logger.error(f"Tabelas dispon√≠veis: {nomes_tabelas}")
                return False
                
            if tabela_bemol not in nomes_tabelas:
                logger.error(f"‚ùå Tabela {tabela_bemol} n√£o encontrada")
                logger.error(f"Tabelas dispon√≠veis: {nomes_tabelas}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao listar tabelas: {e}")
            return False
        
        # Verifica se as tabelas t√™m dados
        try:
            logger.info(f"üìä Verificando dados da tabela {tabela_magalu}")
            count_magalu = spark.table(tabela_magalu).count()
            logger.info(f"Tabela {tabela_magalu}: {count_magalu} registros")
            
            if count_magalu == 0:
                logger.error(f"‚ùå Tabela {tabela_magalu} est√° vazia")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao verificar tabela {tabela_magalu}: {e}")
            return False
            
        try:
            logger.info(f"üìä Verificando dados da tabela {tabela_bemol}")
            count_bemol = spark.table(tabela_bemol).count()
            logger.info(f"Tabela {tabela_bemol}: {count_bemol} registros")
            
            if count_bemol == 0:
                logger.error(f"‚ùå Tabela {tabela_bemol} est√° vazia")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao verificar tabela {tabela_bemol}: {e}")
            return False
        
        # Verifica se as tabelas t√™m as colunas necess√°rias
        try:
            logger.info("üîç Verificando estrutura das tabelas...")
            
            # Verifica tabela Magalu
            df_magalu_sample = spark.table(tabela_magalu).limit(1).toPandas()
            colunas_necessarias = ["title", "price", "url", "embedding"]
            colunas_faltantes = [col for col in colunas_necessarias if col not in df_magalu_sample.columns]
            
            if colunas_faltantes:
                logger.error(f"‚ùå Tabela {tabela_magalu} est√° faltando colunas: {colunas_faltantes}")
                logger.info(f"Colunas dispon√≠veis: {list(df_magalu_sample.columns)}")
                return False
                
            # Verifica tabela Bemol
            df_bemol_sample = spark.table(tabela_bemol).limit(1).toPandas()
            colunas_faltantes = [col for col in colunas_necessarias if col not in df_bemol_sample.columns]
            
            if colunas_faltantes:
                logger.error(f"‚ùå Tabela {tabela_bemol} est√° faltando colunas: {colunas_faltantes}")
                logger.info(f"Colunas dispon√≠veis: {list(df_bemol_sample.columns)}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao verificar estrutura das tabelas: {e}")
            return False
        
        logger.info(f"‚úÖ Valida√ß√£o conclu√≠da com sucesso:")
        logger.info(f"  - {tabela_magalu}: {count_magalu} produtos")
        logger.info(f"  - {tabela_bemol}: {count_bemol} produtos")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro geral na valida√ß√£o de par√¢metros: {e}")
        return False


def executar_pipeline_benchmarking(
    tabela_magalu: str = "silver.embeddings_magalu_completo",
    tabela_bemol: str = "silver.embeddings_bemol"
) -> Tuple[pd.DataFrame, str, str, str]:
    """
    Executa pipeline completo de benchmarking de produtos.
    
    Args:
        tabela_magalu: Nome da tabela do Magalu
        tabela_bemol: Nome da tabela da Bemol
        
    Returns:
        Tuple: (DataFrame_final, caminho_excel, caminho_html, nome_tempview)
    """
    try:
        logger.info("üöÄ Iniciando pipeline de benchmarking")
        
        # Valida par√¢metros
        logger.info("üîç Iniciando valida√ß√£o de par√¢metros...")
        if not validar_parametros_pipeline(tabela_magalu, tabela_bemol):
            error_msg = f"‚ùå Valida√ß√£o de par√¢metros falhou. Verifique as tabelas de entrada:"
            error_msg += f"\n  - Tabela Magalu: {tabela_magalu}"
            error_msg += f"\n  - Tabela Bemol: {tabela_bemol}"
            error_msg += f"\n\nVerifique se:"
            error_msg += f"\n  1. As tabelas existem no cat√°logo"
            error_msg += f"\n  2. As tabelas cont√™m dados"
            error_msg += f"\n  3. As tabelas t√™m as colunas necess√°rias: title, price, url, embedding"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # Carrega dados das tabelas
        logger.info("üìä Carregando dados das tabelas")
        df_magalu = spark.table(tabela_magalu).toPandas()
        df_bemol = spark.table(tabela_bemol).toPandas()
        
        logger.info(f"Dados carregados: Magalu ({len(df_magalu)} produtos), Bemol ({len(df_bemol)} produtos)")
        
        # Processa embeddings e similaridade
        logger.info("üîç Processando embeddings e similaridade")
        df_final = processar_embeddings_completos(df_magalu, df_bemol)
        
        # Gera relat√≥rios
        logger.info("üìã Gerando relat√≥rios")
        caminho_excel, caminho_html, nome_tempview = gerar_relatorio_benchmarking(df_final)
        
        # Calcula estat√≠sticas
        stats = obter_estatisticas_relatorio(df_final)
        
        logger.info("‚úÖ Pipeline de benchmarking conclu√≠do com sucesso")
        logger.info(f"üìä Estat√≠sticas: {stats}")
        
        return df_final, caminho_excel, caminho_html, nome_tempview
        
    except Exception as e:
        logger.error(f"‚ùå Erro no pipeline de benchmarking: {e}")
        raise


def executar_pipeline_completo(
    tabela_magalu: str = "silver.embeddings_magalu_completo",
    tabela_bemol: str = "silver.embeddings_bemol",
    caminho_excel: Optional[str] = None,
    caminho_html: Optional[str] = None,
    nome_tempview: Optional[str] = None
) -> Dict[str, Any]:
    """
    Executa pipeline completo com gera√ß√£o de relat√≥rios.
    
    Args:
        tabela_magalu: Nome da tabela do Magalu
        tabela_bemol: Nome da tabela da Bemol
        caminho_excel: Caminho opcional para arquivo Excel
        caminho_html: Caminho opcional para arquivo HTML
        nome_tempview: Nome opcional para TempView
        
    Returns:
        Dict: Resultados do pipeline
    """
    try:
        # Executa pipeline de benchmarking
        df_final, excel_path, html_path, tempview_name = executar_pipeline_benchmarking(
            tabela_magalu, tabela_bemol
        )
        
        # Calcula estat√≠sticas
        stats = obter_estatisticas_relatorio(df_final)
        
        # Prepara resultados
        resultados = {
            "df_final": df_final,
            "caminho_excel": excel_path,
            "caminho_html": html_path,
            "nome_tempview": tempview_name,
            "estatisticas": stats,
            "status": "sucesso"
        }
        
        logger.info("üéâ Pipeline completo executado com sucesso")
        return resultados
        
    except Exception as e:
        logger.error(f"‚ùå Erro no pipeline completo: {e}")
        return {
            "status": "erro",
            "erro": str(e)
        }


def executar_pipeline_com_email(
    tabela_magalu: str = "silver.embeddings_magalu_completo",
    tabela_bemol: str = "silver.embeddings_bemol",
    destinatarios_email: Optional[list] = None,
    assunto_email: Optional[str] = None,
    remetente: str = "caiomiguel@bemol.com.br"
) -> Dict[str, Any]:
    """
    Executa pipeline completo com envio de email.
    
    Args:
        tabela_magalu: Nome da tabela do Magalu
        tabela_bemol: Nome da tabela da Bemol
        destinatarios_email: Lista de emails destinat√°rios
        assunto_email: Assunto do email
        remetente: Email do remetente
        
    Returns:
        Dict: Resultados do pipeline
    """
    try:
        # Executa pipeline de benchmarking
        df_final, excel_path, html_path, tempview_name = executar_pipeline_benchmarking(
            tabela_magalu, tabela_bemol
        )
        
        # Calcula estat√≠sticas
        stats = obter_estatisticas_relatorio(df_final)
        
        # Envia email
        logger.info("üìß Enviando relat√≥rio por email")
        email_enviado = enviar_email_relatorio(
            df_final=df_final,
            stats=stats,
            caminho_excel=excel_path,
            caminho_html=html_path,
            destinatarios=destinatarios_email,
            assunto=assunto_email,
            remetente=remetente
        )
        
        # Prepara resultados
        resultados = {
            "df_final": df_final,
            "caminho_excel": excel_path,
            "caminho_html": html_path,
            "nome_tempview": tempview_name,
            "estatisticas": stats,
            "email_enviado": email_enviado,
            "status": "sucesso"
        }
        
        logger.info("üéâ Pipeline com email executado com sucesso")
        return resultados
        
    except Exception as e:
        logger.error(f"‚ùå Erro no pipeline com email: {e}")
        return {
            "status": "erro",
            "erro": str(e)
        }


def executar_pipeline_completo_com_email(
    tabela_magalu: str = "silver.embeddings_magalu_completo",
    tabela_bemol: str = "silver.embeddings_bemol",
    caminho_excel: Optional[str] = None,
    caminho_html: Optional[str] = None,
    nome_tempview: Optional[str] = None,
    enviar_email: bool = False,
    destinatarios_email: Optional[list] = None,
    assunto_email: Optional[str] = None,
    remetente: str = "caiomiguel@bemol.com.br"
) -> Dict[str, Any]:
    """
    Executa pipeline completo com op√ß√£o de envio de email.
    
    Args:
        tabela_magalu: Nome da tabela do Magalu
        tabela_bemol: Nome da tabela da Bemol
        caminho_excel: Caminho opcional para arquivo Excel
        caminho_html: Caminho opcional para arquivo HTML
        nome_tempview: Nome opcional para TempView
        enviar_email: Se deve enviar email
        destinatarios_email: Lista de emails destinat√°rios
        assunto_email: Assunto do email
        remetente: Email do remetente
        
    Returns:
        Dict: Resultados do pipeline
    """
    try:
        if enviar_email:
            return executar_pipeline_com_email(
                tabela_magalu=tabela_magalu,
                tabela_bemol=tabela_bemol,
                destinatarios_email=destinatarios_email,
                assunto_email=assunto_email,
                remetente=remetente
            )
        else:
            return executar_pipeline_completo(
                tabela_magalu=tabela_magalu,
                tabela_bemol=tabela_bemol,
                caminho_excel=caminho_excel,
                caminho_html=caminho_html,
                nome_tempview=nome_tempview
            )
            
    except Exception as e:
        logger.error(f"‚ùå Erro no pipeline completo com email: {e}")
        return {
            "status": "erro",
            "erro": str(e)
        } 