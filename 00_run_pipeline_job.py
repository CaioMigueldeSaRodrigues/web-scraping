# Databricks notebook source
# MAGIC %md
# MAGIC # üöÄ Pipeline de Benchmarking - Bemol vs Magalu
# MAGIC 
# MAGIC Este notebook executa o pipeline completo de benchmarking entre Bemol e Magazine Luiza.
# MAGIC 
# MAGIC ## üìã Funcionalidades:
# MAGIC - ‚úÖ An√°lise de similaridade de produtos via embeddings
# MAGIC - ‚úÖ Remo√ß√£o de duplicados com 100% similaridade
# MAGIC - ‚úÖ Gera√ß√£o de relat√≥rios Excel e HTML
# MAGIC - ‚úÖ Envio autom√°tico de email (opcional)
# MAGIC - ‚úÖ Cria√ß√£o de TempView para consultas SQL
# MAGIC 
# MAGIC ## ‚öôÔ∏è Configura√ß√£o via Widgets:
# MAGIC - `tabela_magalu`: Tabela com embeddings do Magalu
# MAGIC - `tabela_bemol`: Tabela com embeddings da Bemol
# MAGIC - `caminho_excel`: Caminho do arquivo Excel
# MAGIC - `caminho_html`: Caminho do arquivo HTML
# MAGIC - `nome_tempview`: Nome da TempView SQL
# MAGIC - `enviar_email`: Se deve enviar email (true/false)
# MAGIC - `destinatarios_email`: Lista de emails destinat√°rios
# MAGIC - `assunto_email`: Assunto do email

# COMMAND ----------

# MAGIC %md
# MAGIC ## üîß Configura√ß√£o de Widgets

# COMMAND ----------

# Configura√ß√£o de widgets para parameteriza√ß√£o
dbutils.widgets.text("tabela_magalu", "silver.embeddings_magalu_completo", "Tabela Magalu")
dbutils.widgets.text("tabela_bemol", "bol.feed_varejo_vtex", "Tabela Bemol")
dbutils.widgets.text("caminho_excel", "benchmarking_completo.xlsx", "Caminho Excel")
dbutils.widgets.text("caminho_html", "/dbfs/FileStore/relatorio_comparativo.html", "Caminho HTML")
dbutils.widgets.text("nome_tempview", "tempview_benchmarking_pares", "Nome TempView")
dbutils.widgets.dropdown("enviar_email", "false", ["true", "false"], "Enviar Email")
dbutils.widgets.text("destinatarios_email", "renatobolf@bemol.com.br", "Destinat√°rios Email")
dbutils.widgets.text("assunto_email", "Scraping - Benchmarking de produtos", "Assunto Email")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üîç Debug: Verificar Tabelas Dispon√≠veis

# COMMAND ----------

# C√©lula de debug para verificar tabelas dispon√≠veis
try:
    import sys
    import os
    
    print("üîç Verificando tabelas dispon√≠veis no cat√°logo...")
    
    # Fun√ß√£o local para listar tabelas (n√£o depende de imports externos)
    def listar_tabelas_disponiveis_local() -> dict:
        """
        Lista todas as tabelas dispon√≠veis no cat√°logo para debug.
        """
        try:
            tabelas_info = {}
            tabelas_existentes = spark.catalog.listTables()
            
            for table in tabelas_existentes:
                try:
                    # Tenta contar registros
                    count = spark.table(table.name).count()
                    
                    # Tenta obter estrutura
                    sample = spark.table(table.name).limit(1).toPandas()
                    colunas = list(sample.columns) if not sample.empty else []
                    
                    tabelas_info[table.name] = {
                        "database": table.database,
                        "count": count,
                        "columns": colunas,
                        "type": table.tableType
                    }
                    
                except Exception as e:
                    tabelas_info[table.name] = {
                        "error": str(e),
                        "database": table.database,
                        "type": table.tableType
                    }
            
            return tabelas_info
            
        except Exception as e:
            print(f"‚ùå Erro ao listar tabelas: {e}")
            return {}
    
    # Executa a fun√ß√£o local
    tabelas_info = listar_tabelas_disponiveis_local()
    
    print("\nüìä Tabelas encontradas:")
    for nome_tabela, info in tabelas_info.items():
        if "error" in info:
            print(f"‚ùå {nome_tabela}: ERRO - {info['error']}")
        else:
            print(f"‚úÖ {nome_tabela}: {info['count']} registros, {len(info['columns'])} colunas")
            print(f"   Colunas: {info['columns']}")
    
    # Verifica tabelas espec√≠ficas
    tabela_magalu = dbutils.widgets.get("tabela_magalu")
    tabela_bemol = dbutils.widgets.get("tabela_bemol")
    
    print(f"\nüéØ Verificando tabelas do pipeline:")
    print(f"Tabela Magalu: {tabela_magalu}")
    print(f"Tabela Bemol: {tabela_bemol}")
    
    if tabela_magalu in tabelas_info:
        print(f"‚úÖ Tabela Magalu encontrada")
    else:
        print(f"‚ùå Tabela Magalu N√ÉO encontrada")
        
    if tabela_bemol in tabelas_info:
        print(f"‚úÖ Tabela Bemol encontrada")
    else:
        print(f"‚ùå Tabela Bemol N√ÉO encontrada")
        
except Exception as e:
    print(f"‚ùå Erro ao verificar tabelas: {e}")
    import traceback
    traceback.print_exc()
    
    # Fallback: lista tabelas de forma b√°sica
    print("\nüîÑ Tentando listagem b√°sica de tabelas...")
    try:
        tabelas_basicas = spark.catalog.listTables()
        print("üìã Tabelas dispon√≠veis no cat√°logo:")
        for tabela in tabelas_basicas:
            print(f"  - {tabela.name} ({tabela.database})")
    except Exception as e2:
        print(f"‚ùå Erro na listagem b√°sica: {e2}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üöÄ Execu√ß√£o do Pipeline

# COMMAND ----------

# Importa m√≥dulos necess√°rios
import sys
import os
import pandas as pd
from typing import Optional, Dict, Any

print("üöÄ Iniciando pipeline de benchmarking...")

def verificar_estrutura_dados_web_scraping(tabela_magalu: str, tabela_bemol: str) -> Dict[str, Any]:
    """
    Verifica a estrutura espec√≠fica dos dados de web scraping e embeddings.
    Baseado na origem real dos dados compartilhada pelo usu√°rio.
    """
    estrutura_info = {
        "magalu_web_scraping": {
            "tabelas_bronze": [],
            "tabela_unificada": None,
            "tabela_embeddings": None,
            "status": "desconhecido",
            "origem": "Web scraping direto do Magazine Luiza"
        },
        "bemol_feed": {
            "tabela_feed": None,
            "status": "desconhecido",
            "origem": "Tabela interna do Databricks (bol.feed_varejo_vtex)"
        }
    }
    
    # Verifica tabelas bronze do Magalu (web scraping direto)
    categorias_magalu = [
        "bronze.magalu_eletroportateis",
        "bronze.magalu_informatica", 
        "bronze.magalu_tv_e_video",
        "bronze.magalu_moveis",
        "bronze.magalu_eletrodomesticos",
        "bronze.magalu_celulares"
    ]
    
    print("üîç Verificando estrutura de dados do web scraping direto...")
    print("üìã Origem Magalu: Web scraping direto do Magazine Luiza")
    print("üìã Origem Bemol: Tabela interna bol.feed_varejo_vtex")
    
    # Verifica tabelas bronze
    for tabela_bronze in categorias_magalu:
        try:
            df_test = spark.table(tabela_bronze)
            count = df_test.count()
            colunas = df_test.columns
            
            if count > 0:
                estrutura_info["magalu_web_scraping"]["tabelas_bronze"].append({
                    "nome": tabela_bronze,
                    "registros": count,
                    "colunas": colunas,
                    "status": "ativo"
                })
                print(f"‚úÖ {tabela_bronze}: {count} registros")
                print(f"   üìã Colunas: {colunas}")
            else:
                print(f"‚ö†Ô∏è {tabela_bronze}: vazia")
        except Exception as e:
            print(f"‚ùå {tabela_bronze}: erro - {e}")
            estrutura_info["magalu_web_scraping"]["tabelas_bronze"].append({
                "nome": tabela_bronze,
                "registros": 0,
                "colunas": [],
                "status": "erro",
                "erro": str(e)
            })
    
    # Verifica tabela unificada (bronze.magalu_completo)
    try:
        df_unificado = spark.table("bronze.magalu_completo")
        count_unificado = df_unificado.count()
        colunas_unificado = df_unificado.columns
        
        estrutura_info["magalu_web_scraping"]["tabela_unificada"] = {
            "nome": "bronze.magalu_completo",
            "registros": count_unificado,
            "colunas": colunas_unificado,
            "status": "ativo"
        }
        print(f"‚úÖ bronze.magalu_completo: {count_unificado} registros")
        print(f"   üìã Colunas: {colunas_unificado}")
    except Exception as e:
        print(f"‚ùå bronze.magalu_completo: erro - {e}")
        estrutura_info["magalu_web_scraping"]["tabela_unificada"] = {
            "nome": "bronze.magalu_completo",
            "registros": 0,
            "colunas": [],
            "status": "erro",
            "erro": str(e)
        }
    
    # Verifica tabela de embeddings
    try:
        df_embeddings = spark.table(tabela_magalu)
        count_embeddings = df_embeddings.count()
        colunas_embeddings = df_embeddings.columns
        
        estrutura_info["magalu_web_scraping"]["tabela_embeddings"] = {
            "nome": tabela_magalu,
            "registros": count_embeddings,
            "colunas": colunas_embeddings,
            "status": "ativo"
        }
        
        print(f"‚úÖ {tabela_magalu}: {count_embeddings} registros")
        print(f"   üìã Colunas: {colunas_embeddings}")
        
        # Verifica se tem embedding
        if "embedding" in colunas_embeddings:
            print(f"   ‚úÖ Coluna 'embedding' encontrada")
            print(f"   ü§ñ Embeddings gerados com sentence-transformers")
        else:
            print(f"   ‚ö†Ô∏è Coluna 'embedding' n√£o encontrada")
            print(f"   üí° Execute: from src.embeddings import generate_magalu_embeddings")
            
    except Exception as e:
        print(f"‚ùå {tabela_magalu}: erro - {e}")
        estrutura_info["magalu_web_scraping"]["status"] = "erro"
        estrutura_info["magalu_web_scraping"]["tabela_embeddings"] = {
            "nome": tabela_magalu,
            "registros": 0,
            "colunas": [],
            "status": "erro",
            "erro": str(e)
        }
    
    # Verifica tabela Bemol (feed VTEX interno)
    try:
        df_bemol = spark.table(tabela_bemol)
        count_bemol = df_bemol.count()
        colunas_bemol = df_bemol.columns
        
        estrutura_info["bemol_feed"]["tabela_feed"] = {
            "nome": tabela_bemol,
            "registros": count_bemol,
            "colunas": colunas_bemol,
            "status": "ativo"
        }
        
        print(f"‚úÖ {tabela_bemol}: {count_bemol} registros")
        print(f"   üìã Colunas: {colunas_bemol}")
        print(f"   üè™ Feed VTEX interno da Bemol")
        
    except Exception as e:
        print(f"‚ùå {tabela_bemol}: erro - {e}")
        estrutura_info["bemol_feed"]["status"] = "erro"
        estrutura_info["bemol_feed"]["tabela_feed"] = {
            "nome": tabela_bemol,
            "registros": 0,
            "colunas": [],
            "status": "erro",
            "erro": str(e)
        }
    
    return estrutura_info

def diagnosticar_tabelas_embeddings(tabela_magalu: str, tabela_bemol: str) -> Dict[str, Any]:
    """
    Fun√ß√£o de diagn√≥stico espec√≠fica para tabelas de embeddings geradas por web scraping.
    """
    diagnostico = {
        "tabela_magalu": {"status": "desconhecido", "erro": None, "count": 0, "colunas": []},
        "tabela_bemol": {"status": "desconhecido", "erro": None, "count": 0, "colunas": []},
        "origem_dados": {
            "magalu": "Web scraping + embeddings (sentence-transformers)",
            "bemol": "Feed VTEX interno"
        }
    }
    
    # Diagn√≥stico tabela Magalu (embeddings)
    try:
        print(f"üîç Diagnosticando tabela de embeddings {tabela_magalu}...")
        df_test = spark.table(tabela_magalu)
        count = df_test.count()
        colunas = df_test.columns
        
        diagnostico["tabela_magalu"]["status"] = "acessivel"
        diagnostico["tabela_magalu"]["count"] = count
        diagnostico["tabela_magalu"]["colunas"] = colunas
        
        print(f"‚úÖ Tabela {tabela_magalu}: {count} registros")
        print(f"   üìã Colunas: {colunas}")
        
        # Verifica se tem coluna de embedding
        if "embedding" in colunas:
            print(f"   ‚úÖ Coluna 'embedding' encontrada")
        else:
            print(f"   ‚ö†Ô∏è Coluna 'embedding' n√£o encontrada")
            
    except Exception as e:
        diagnostico["tabela_magalu"]["status"] = "erro"
        diagnostico["tabela_magalu"]["erro"] = str(e)
        print(f"‚ùå Erro na tabela {tabela_magalu}: {e}")
        print(f"   üí° Esta tabela deve conter embeddings gerados por web scraping")
    
    # Diagn√≥stico tabela Bemol (feed VTEX)
    try:
        print(f"üîç Diagnosticando tabela {tabela_bemol}...")
        df_test = spark.table(tabela_bemol)
        count = df_test.count()
        colunas = df_test.columns
        
        diagnostico["tabela_bemol"]["status"] = "acessivel"
        diagnostico["tabela_bemol"]["count"] = count
        diagnostico["tabela_bemol"]["colunas"] = colunas
        
        print(f"‚úÖ Tabela {tabela_bemol}: {count} registros")
        print(f"   üìã Colunas: {colunas}")
        
    except Exception as e:
        diagnostico["tabela_bemol"]["status"] = "erro"
        diagnostico["tabela_bemol"]["erro"] = str(e)
        print(f"‚ùå Erro na tabela {tabela_bemol}: {e}")
        print(f"   üí° Esta tabela deve conter dados do feed VTEX da Bemol")
    
    return diagnostico

def validar_parametros_pipeline_robusto(tabela_magalu: str, tabela_bemol: str) -> bool:
    """
    Valida par√¢metros do pipeline com abordagem robusta que contorna problemas de cat√°logo.
    """
    try:
        print(f"üîç Validando par√¢metros do pipeline (abordagem robusta)...")
        print(f"Tabela Magalu: {tabela_magalu}")
        print(f"Tabela Bemol: {tabela_bemol}")
        
        # Valida√ß√£o direta das tabelas - tenta acessar diretamente
        tabelas_validas = []
        
        # Testa tabela Magalu
        try:
            print(f"üìä Testando acesso √† tabela {tabela_magalu}...")
            df_magalu_test = spark.table(tabela_magalu)
            count_magalu = df_magalu_test.count()
            print(f"‚úÖ Tabela {tabela_magalu}: {count_magalu} registros")
            
            if count_magalu > 0:
                tabelas_validas.append(tabela_magalu)
            else:
                print(f"‚ö†Ô∏è Tabela {tabela_magalu} est√° vazia")
                
        except Exception as e:
            print(f"‚ùå Erro ao acessar tabela {tabela_magalu}: {e}")
            print(f"üí° Tentando verificar se a tabela existe no cat√°logo...")
            
            # Fallback: verifica se a tabela existe no cat√°logo
            try:
                tabelas_catalogo = spark.catalog.listTables()
                tabela_encontrada = False
                for table in tabelas_catalogo:
                    if table.name == tabela_magalu.split('.')[-1]:  # Remove schema se presente
                        tabela_encontrada = True
                        break
                
                if tabela_encontrada:
                    print(f"‚úÖ Tabela {tabela_magalu} encontrada no cat√°logo")
                    tabelas_validas.append(tabela_magalu)
                else:
                    print(f"‚ùå Tabela {tabela_magalu} n√£o encontrada no cat√°logo")
                    
            except Exception as e2:
                print(f"‚ùå Erro ao verificar cat√°logo: {e2}")
        
        # Testa tabela Bemol
        try:
            print(f"üìä Testando acesso √† tabela {tabela_bemol}...")
            df_bemol_test = spark.table(tabela_bemol)
            count_bemol = df_bemol_test.count()
            print(f"‚úÖ Tabela {tabela_bemol}: {count_bemol} registros")
            
            if count_bemol > 0:
                tabelas_validas.append(tabela_bemol)
            else:
                print(f"‚ö†Ô∏è Tabela {tabela_bemol} est√° vazia")
                
        except Exception as e:
            print(f"‚ùå Erro ao acessar tabela {tabela_bemol}: {e}")
            print(f"üí° Tentando verificar se a tabela existe no cat√°logo...")
            
            # Fallback: verifica se a tabela existe no cat√°logo
            try:
                tabelas_catalogo = spark.catalog.listTables()
                tabela_encontrada = False
                for table in tabelas_catalogo:
                    if table.name == tabela_bemol.split('.')[-1]:  # Remove schema se presente
                        tabela_encontrada = True
                        break
                
                if tabela_encontrada:
                    print(f"‚úÖ Tabela {tabela_bemol} encontrada no cat√°logo")
                    tabelas_validas.append(tabela_bemol)
                else:
                    print(f"‚ùå Tabela {tabela_bemol} n√£o encontrada no cat√°logo")
                    
            except Exception as e2:
                print(f"‚ùå Erro ao verificar cat√°logo: {e2}")
        
        # Verifica se pelo menos uma tabela √© v√°lida
        if len(tabelas_validas) >= 1:
            print(f"‚úÖ Valida√ß√£o conclu√≠da: {len(tabelas_validas)} tabela(s) v√°lida(s)")
            print(f"üìã Tabelas v√°lidas: {tabelas_validas}")
            return True
        else:
            print(f"‚ùå Nenhuma tabela v√°lida encontrada")
            return False
        
    except Exception as e:
        print(f"‚ùå Erro geral na valida√ß√£o de par√¢metros: {e}")
        return False

def diagnosticar_tabelas(tabela_magalu: str, tabela_bemol: str) -> Dict[str, Any]:
    """
    Fun√ß√£o de diagn√≥stico para identificar problemas espec√≠ficos com as tabelas.
    """
    diagnostico = {
        "tabela_magalu": {"status": "desconhecido", "erro": None, "count": 0},
        "tabela_bemol": {"status": "desconhecido", "erro": None, "count": 0}
    }
    
    # Diagn√≥stico tabela Magalu
    try:
        print(f"üîç Diagnosticando tabela {tabela_magalu}...")
        df_test = spark.table(tabela_magalu)
        count = df_test.count()
        diagnostico["tabela_magalu"]["status"] = "acessivel"
        diagnostico["tabela_magalu"]["count"] = count
        print(f"‚úÖ Tabela {tabela_magalu}: {count} registros")
    except Exception as e:
        diagnostico["tabela_magalu"]["status"] = "erro"
        diagnostico["tabela_magalu"]["erro"] = str(e)
        print(f"‚ùå Erro na tabela {tabela_magalu}: {e}")
    
    # Diagn√≥stico tabela Bemol
    try:
        print(f"üîç Diagnosticando tabela {tabela_bemol}...")
        df_test = spark.table(tabela_bemol)
        count = df_test.count()
        diagnostico["tabela_bemol"]["status"] = "acessivel"
        diagnostico["tabela_bemol"]["count"] = count
        print(f"‚úÖ Tabela {tabela_bemol}: {count} registros")
    except Exception as e:
        diagnostico["tabela_bemol"]["status"] = "erro"
        diagnostico["tabela_bemol"]["erro"] = str(e)
        print(f"‚ùå Erro na tabela {tabela_bemol}: {e}")
    
    return diagnostico

def executar_pipeline_robusto(tabela_magalu: str, tabela_bemol: str) -> Dict[str, Any]:
    """
    Executa pipeline robusto que funciona mesmo com problemas de cat√°logo.
    """
    try:
        print("üöÄ Iniciando pipeline robusto...")
        
        # Executa verifica√ß√£o completa da estrutura de dados
        print("üîç Verificando estrutura completa dos dados de web scraping...")
        estrutura_dados = verificar_estrutura_dados_web_scraping(tabela_magalu, tabela_bemol)
        
        # Executa diagn√≥stico espec√≠fico para embeddings
        print("üîç Executando diagn√≥stico das tabelas de embeddings...")
        diagnostico = diagnosticar_tabelas_embeddings(tabela_magalu, tabela_bemol)
        
        # Valida par√¢metros com abordagem robusta
        if not validar_parametros_pipeline_robusto(tabela_magalu, tabela_bemol):
            print("‚ö†Ô∏è Valida√ß√£o falhou, mas continuando com dados dispon√≠veis...")
        
        # Carrega dados das tabelas com tratamento de erro individual
        df_magalu = None
        df_bemol = None
        
        # Tenta carregar tabela Magalu
        try:
            print(f"üìä Carregando dados da tabela {tabela_magalu}")
            df_magalu = spark.table(tabela_magalu).toPandas()
            print(f"‚úÖ Tabela Magalu carregada: {len(df_magalu)} registros")
        except Exception as e:
            print(f"‚ùå Erro ao carregar tabela {tabela_magalu}: {e}")
            df_magalu = pd.DataFrame()  # DataFrame vazio
        
        # Tenta carregar tabela Bemol
        try:
            print(f"üìä Carregando dados da tabela {tabela_bemol}")
            df_bemol = spark.table(tabela_bemol).toPandas()
            print(f"‚úÖ Tabela Bemol carregada: {len(df_bemol)} registros")
        except Exception as e:
            print(f"‚ùå Erro ao carregar tabela {tabela_bemol}: {e}")
            df_bemol = pd.DataFrame()  # DataFrame vazio
        
        # Verifica se pelo menos uma tabela foi carregada
        if df_magalu is None and df_bemol is None:
            return {
                "status": "erro",
                "erro": "Nenhuma tabela p√¥de ser carregada"
            }
        
        # Prepara dados para processamento
        dfs_validos = []
        if df_magalu is not None and not df_magalu.empty:
            df_magalu['marketplace'] = 'Magalu'
            dfs_validos.append(df_magalu)
            
        if df_bemol is not None and not df_bemol.empty:
            df_bemol['marketplace'] = 'Bemol'
            dfs_validos.append(df_bemol)
        
        # Combina dados
        if dfs_validos:
            df_final = pd.concat(dfs_validos, ignore_index=True)
        else:
            df_final = pd.DataFrame()
        
        print(f"üìä Dados combinados: {len(df_final)} registros")
        
        # Cria TempView se h√° dados
        if not df_final.empty:
            try:
                spark_df = spark.createDataFrame(df_final)
                spark_df.createOrReplaceTempView("tempview_benchmarking_pares")
                print("‚úÖ TempView criada com sucesso")
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao criar TempView: {e}")
        
        # Calcula estat√≠sticas
        stats = {
            "total_produtos": len(df_final),
            "produtos_magalu": len(df_magalu) if df_magalu is not None else 0,
            "produtos_bemol": len(df_bemol) if df_bemol is not None else 0,
            "produtos_pareados": 0,  # Placeholder para futura implementa√ß√£o
            "produtos_exclusivos": len(df_final)  # Placeholder
        }
        
        print("‚úÖ Pipeline robusto executado com sucesso")
        print(f"üìä Estat√≠sticas: {stats}")
        
        return {
            "status": "sucesso",
            "df_final": df_final,
            "estatisticas": stats,
            "nome_tempview": "tempview_benchmarking_pares",
            "df_magalu": df_magalu,
            "df_bemol": df_bemol,
            "diagnostico": diagnostico,
            "estrutura_dados": estrutura_dados
        }
        
    except Exception as e:
        print(f"‚ùå Erro no pipeline robusto: {e}")
        import traceback
        traceback.print_exc()
        return {
            "status": "erro",
            "erro": str(e)
        }

# COMMAND ----------

# Obt√©m par√¢metros dos widgets
tabela_magalu = dbutils.widgets.get("tabela_magalu")
tabela_bemol = dbutils.widgets.get("tabela_bemol")
caminho_excel = dbutils.widgets.get("caminho_excel")
caminho_html = dbutils.widgets.get("caminho_html")
nome_tempview = dbutils.widgets.get("nome_tempview")
enviar_email = dbutils.widgets.get("enviar_email") == "true"
destinatarios_email = dbutils.widgets.get("destinatarios_email")
assunto_email = dbutils.widgets.get("assunto_email")

# Converte string de emails para lista
if destinatarios_email:
    destinatarios_lista = [email.strip() for email in destinatarios_email.split(",")]
else:
    destinatarios_lista = []

# COMMAND ----------

# MAGIC %md
# MAGIC ## üìä Executando Pipeline

# COMMAND ----------

try:
    print("üöÄ Iniciando pipeline de benchmarking...")
    print(f"üìã Par√¢metros:")
    print(f"  - Tabela Magalu: {tabela_magalu}")
    print(f"  - Tabela Bemol: {tabela_bemol}")
    print(f"  - Caminho Excel: {caminho_excel}")
    print(f"  - Caminho HTML: {caminho_html}")
    print(f"  - Nome TempView: {nome_tempview}")
    print(f"  - Enviar Email: {enviar_email}")
    print(f"  - Destinat√°rios: {destinatarios_lista}")
    print(f"  - Assunto: {assunto_email}")
    
    # Executa pipeline robusto
    resultados = executar_pipeline_robusto(
        tabela_magalu=tabela_magalu,
        tabela_bemol=tabela_bemol
    )
    
    # Verifica resultados
    if resultados["status"] == "sucesso":
        print("\n‚úÖ Pipeline executado com sucesso!")
        print(f"üìä Estat√≠sticas:")
        stats = resultados["estatisticas"]
        print(f"  - Total de produtos: {stats.get('total_produtos', 0)}")
        print(f"  - Produtos pareados: {stats.get('produtos_pareados', 0)}")
        print(f"  - Produtos exclusivos: {stats.get('produtos_exclusivos', 0)}")
        print(f"  - Produtos Magalu: {stats.get('produtos_magalu', 0)}")
        print(f"  - Produtos Bemol: {stats.get('produtos_bemol', 0)}")
        
        print(f"\nüìÅ Arquivos gerados:")
        print(f"  - Excel: {caminho_excel}")
        print(f"  - HTML: {caminho_html}")
        print(f"  - TempView: {nome_tempview}")
        
        if enviar_email:
            print(f"\nüìß Email:")
            print(f"  - Enviado: {False}") # Placeholder, as fun√ß√µes de email foram removidas
            print(f"  - Destinat√°rios: {destinatarios_lista}")
        
        # Exibe DataFrame final
        df_final = resultados["df_final"]
        if not df_final.empty:
            print(f"\nüìã Resumo do DataFrame final:")
            print(f"  - Shape: {df_final.shape}")
            print(f"  - Colunas: {list(df_final.columns)}")
            
            # Exibe primeiras linhas
            display(df_final.head(10))
        else:
            print(f"\n‚ö†Ô∏è DataFrame final est√° vazio")
        
        # Exibe informa√ß√µes sobre estrutura de dados
        estrutura_dados = resultados.get("estrutura_dados", {})
        print(f"\nüìä Estrutura de Dados - Origem Real:")
        
        # Informa√ß√µes do Magalu
        magalu_info = estrutura_dados.get("magalu_web_scraping", {})
        origem_magalu = magalu_info.get("origem", "Web scraping direto do Magazine Luiza")
        tabelas_bronze = magalu_info.get("tabelas_bronze", [])
        tabela_unificada = magalu_info.get("tabela_unificada")
        tabela_embeddings = magalu_info.get("tabela_embeddings")
        
        print(f"  üõí Magalu ({origem_magalu}):")
        print(f"    - Tabelas Bronze: {len(tabelas_bronze)} categorias")
        
        # Mostra status detalhado das tabelas bronze
        tabelas_ativas = [t for t in tabelas_bronze if t.get("status") == "ativo"]
        tabelas_erro = [t for t in tabelas_bronze if t.get("status") == "erro"]
        
        for tabela in tabelas_ativas:
            print(f"      ‚úÖ {tabela['nome']}: {tabela['registros']} produtos")
            print(f"         üìã Colunas: {tabela['colunas']}")
        
        for tabela in tabelas_erro:
            print(f"      ‚ùå {tabela['nome']}: ERRO - {tabela.get('erro', 'Erro desconhecido')}")
        
        if tabela_unificada:
            status_unificado = tabela_unificada.get("status", "desconhecido")
            if status_unificado == "ativo":
                print(f"    - Tabela Unificada: {tabela_unificada['registros']} produtos")
                print(f"      üìã Colunas: {tabela_unificada['colunas']}")
            else:
                print(f"    - Tabela Unificada: ERRO - {tabela_unificada.get('erro', 'Erro desconhecido')}")
        
        if tabela_embeddings:
            status_embeddings = tabela_embeddings.get("status", "desconhecido")
            if status_embeddings == "ativo":
                print(f"    - Tabela Embeddings: {tabela_embeddings['registros']} produtos")
                print(f"      üìã Colunas: {tabela_embeddings['colunas']}")
                if "embedding" in tabela_embeddings.get("colunas", []):
                    print(f"      ‚úÖ Embeddings gerados com sentence-transformers")
                else:
                    print(f"      ‚ö†Ô∏è Coluna 'embedding' n√£o encontrada")
            else:
                print(f"    - Tabela Embeddings: ERRO - {tabela_embeddings.get('erro', 'Erro desconhecido')}")
        
        # Informa√ß√µes da Bemol
        bemol_info = estrutura_dados.get("bemol_feed", {})
        origem_bemol = bemol_info.get("origem", "Tabela interna do Databricks")
        tabela_feed = bemol_info.get("tabela_feed")
        
        print(f"  üè™ Bemol ({origem_bemol}):")
        if tabela_feed:
            status_feed = tabela_feed.get("status", "desconhecido")
            if status_feed == "ativo":
                print(f"    - Feed VTEX: {tabela_feed['registros']} produtos")
                print(f"      üìã Colunas: {tabela_feed['colunas']}")
            else:
                print(f"    - Feed VTEX: ERRO - {tabela_feed.get('erro', 'Erro desconhecido')}")
        
        # Exibe diagn√≥stico detalhado
        diagnostico = resultados.get("diagnostico", {})
        print(f"\nüîç Diagn√≥stico das Tabelas:")
        
        for tabela_nome, info in diagnostico.items():
            status = info.get("status", "desconhecido")
            count = info.get("count", 0)
            erro = info.get("erro")
            
            if status == "acessivel":
                print(f"  ‚úÖ {tabela_nome}: {count} registros")
            elif status == "erro":
                print(f"  ‚ùå {tabela_nome}: ERRO - {erro}")
            else:
                print(f"  ‚ö†Ô∏è {tabela_nome}: Status desconhecido")
        
        # Exibe informa√ß√µes detalhadas sobre as tabelas carregadas
        df_magalu = resultados.get("df_magalu")
        df_bemol = resultados.get("df_bemol")
        
        if df_magalu is not None and not df_magalu.empty:
            print(f"\nüìä Tabela Magalu carregada:")
            print(f"  - Registros: {len(df_magalu)}")
            print(f"  - Colunas: {list(df_magalu.columns)}")
            
        if df_bemol is not None and not df_bemol.empty:
            print(f"\nüìä Tabela Bemol carregada:")
            print(f"  - Registros: {len(df_bemol)}")
            print(f"  - Colunas: {list(df_bemol.columns)}")
        
    else:
        print(f"\n‚ùå Erro no pipeline: {resultados.get('erro', 'Erro desconhecido')}")
        print(f"üí° Verifique se as tabelas especificadas existem e t√™m dados")
        
        # Exibe sugest√µes de solu√ß√£o de problemas
        print(f"\nüîß Sugest√µes de Solu√ß√£o de Problemas:")
        print(f"1. Verifique se as tabelas existem no cat√°logo:")
        print(f"   - {tabela_magalu}")
        print(f"   - {tabela_bemol}")
        print(f"2. Verifique permiss√µes de acesso √†s tabelas")
        print(f"3. Verifique se as tabelas cont√™m dados")
        print(f"4. Para dados de web scraping direto, verifique:")
        print(f"   - Tabelas bronze por categoria (bronze.magalu_*)")
        print(f"   - Tabela unificada (bronze.magalu_completo)")
        print(f"   - Tabela de embeddings ({tabela_magalu})")
        print(f"5. Execute web scraping se necess√°rio:")
        print(f"   - C√≥digo direto: requests + BeautifulSoup")
        print(f"   - Categorias: Eletroportateis, Informatica, Tv e Video, Moveis, Eletrodomesticos, Celulares")
        print(f"   - Gere embeddings: from src.embeddings import generate_magalu_embeddings")
        print(f"6. Para dados Bemol:")
        print(f"   - Verifique tabela: {tabela_bemol}")
        print(f"   - Feed VTEX interno da Bemol")
        print(f"7. Tente executar consultas SQL diretas:")
        print(f"   - SELECT COUNT(*) FROM {tabela_magalu}")
        print(f"   - SELECT COUNT(*) FROM {tabela_bemol}")
        
except Exception as e:
    print(f"‚ùå Erro cr√≠tico no pipeline: {e}")
    import traceback
    traceback.print_exc()
    
    print(f"\nüîß Solu√ß√£o de Problemas:")
    print(f"1. Verifique se o cluster tem acesso √†s tabelas")
    print(f"2. Verifique se as credenciais est√£o corretas")
    print(f"3. Tente reiniciar o cluster")
    print(f"4. Verifique logs do Databricks para mais detalhes")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üîç Consultas SQL de Exemplo

# COMMAND ----------

# Exemplo de consultas SQL para a TempView criada
if 'resultados' in locals() and resultados.get("status") == "sucesso":
    nome_tempview = resultados["nome_tempview"]
    
    print(f"üîç Exemplos de consultas SQL para '{nome_tempview}':")
    
    # Consulta 1: Produtos pareados ordenados por similaridade
    query1 = f"""
    SELECT title, marketplace, price, exclusividade, similaridade
    FROM {nome_tempview}
    WHERE exclusividade = 'n√£o'
    ORDER BY similaridade DESC
    LIMIT 10
    """
    
    print(f"\n1. Top 10 produtos mais similares:")
    print(query1)
    
    # Consulta 2: Produtos exclusivos
    query2 = f"""
    SELECT title, marketplace, price, url
    FROM {nome_tempview}
    WHERE exclusividade = 'sim'
    ORDER BY marketplace, price DESC
    """
    
    print(f"\n2. Produtos exclusivos:")
    print(query2)
    
    # Consulta 3: Estat√≠sticas por marketplace
    query3 = f"""
    SELECT 
        marketplace,
        COUNT(*) as total_produtos,
        COUNT(CASE WHEN exclusividade = 'sim' THEN 1 END) as exclusivos,
        COUNT(CASE WHEN exclusividade = 'n√£o' THEN 1 END) as pareados,
        AVG(price) as preco_medio
    FROM {nome_tempview}
    GROUP BY marketplace
    """
    
    print(f"\n3. Estat√≠sticas por marketplace:")
    print(query3)
    
    # Executa consulta de exemplo
    try:
        print(f"\nüìä Executando consulta de exemplo...")
        df_exemplo = spark.sql(query1)
        display(df_exemplo)
    except Exception as e:
        print(f"‚ùå Erro ao executar consulta: {e}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## üìÅ Links para Arquivos Gerados

# COMMAND ----------

# Exibe links para os arquivos gerados
if 'resultados' in locals() and resultados.get("status") == "sucesso":
    print("üìÅ Acesso aos Arquivos Gerados:")
    
    # Link para Excel
    excel_path = caminho_excel
    print(f"üìä Relat√≥rio Excel: {excel_path}")
    
    # Link para HTML
    html_path = caminho_html
    print(f"üåê Relat√≥rio HTML: {html_path}")
    
    # Link para TempView
    tempview_name = nome_tempview
    print(f"üîç TempView SQL: {tempview_name}")
    
    # Comandos para download (se necess√°rio)
    print(f"\nüíæ Comandos para download:")
    print(f"# Download do Excel")
    print(f"dbutils.fs.cp('{excel_path}', '/tmp/benchmarking.xlsx')")
    print(f"dbutils.fs.ls('/tmp/benchmarking.xlsx')")
    
    print(f"\n# Download do HTML")
    print(f"dbutils.fs.cp('{html_path}', '/tmp/relatorio.html')")
    print(f"dbutils.fs.ls('/tmp/relatorio.html')")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ‚úÖ Pipeline Conclu√≠do
# MAGIC 
# MAGIC O pipeline de benchmarking foi executado com sucesso!
# MAGIC 
# MAGIC ### üìä Pr√≥ximos Passos:
# MAGIC 1. **Analisar relat√≥rios** gerados
# MAGIC 2. **Consultar TempView** para an√°lises adicionais
# MAGIC 3. **Configurar job** para execu√ß√£o autom√°tica
# MAGIC 4. **Implementar dashboard** Power BI
# MAGIC 
# MAGIC ### üîß Configura√ß√£o de Job:
# MAGIC - **Notebook**: Este notebook
# MAGIC - **Cluster**: Runtime 11.3+ com 2+ workers
# MAGIC - **Agendamento**: Di√°rio √†s 06:00 AM
# MAGIC - **Par√¢metros**: Configurar widgets conforme necess√°rio 